---
layout: post
title: "MySQL学习笔记(八)：MySQL锁"
subtitle: ""
author: ""
header-style: text
tags:
  - mysql
  - 锁

---



**MySQL中的锁有三类：全局锁、表级锁、行级锁**



### 全局锁

即给整个数据库实例上锁，让整个库都处于只读状态，除查询以外的操作都会被阻塞。server层实现。

> 如果加上全局锁后，客户端由于异常断开，MySQL会自动释放这个锁。



加锁：

```sql
flush tables with read lock;
```

解锁：

```sql
unlock tables;
```



使用场景：做全库逻辑备份

隐患：

- 由于只能查询，所以在此期间业务基本停摆
- 如果在主库上备份，业务停摆；如果在备库上备份，在此期间备库不能执行从主库同步过来的 binlog，会导致主从延迟



那如果备份的时候不加全局锁会发生什么情况呢？

不加锁，**会导致备份出来的库不是同一个逻辑时间点的**，数据从业务逻辑上看是不一致的。

比如在备份过程中先备份了A表，然后执行了一个业务操作，再备份B表，这个业务操作会同时更新A表和B表。那么这个时候备份出来的数据A表还是老版本，而B表已经被更新了，这个备份就是有问题的，是逻辑不一致的。



<u>为了既不影响业务，也要保证备份视图的逻辑一致性</u>，推荐采用另一种全库备份的方法：**`mysqldump -single-transaction`**。导数据之前会启动一个事务，来确保拿到一致性视图。而且由于 MVCC 的支持，在此期间是可以正常更新的。

当然显而易见，这种方法只适用于支持事务的存储引擎，所以这也是为什么推荐使用 Innodb 而不是 MyISAM 的一个原因。







### 表级锁

**server层实现，分两种：表锁和元数据锁(MDL)。**



#### 表锁

> 与全局锁一样，也会在客户端断开时自动释放



加锁：

```sql
lock tables t1 read,t2 write;
```

解锁：

```sql
unlock tables;
```



以上述加锁语句为例，t1加了读锁，t2加了写锁：

- 任何线程都不能写 t1 ，包括本线程
- 只有本线程能读写 t2
- **本线程甚至不能访问除 t1、t2 之外的任何表**，这点很奇怪，不懂为什么这么设计





#### 元数据锁

Meta data lock，MDL

不需要显示使用，访问表的时候会自动加上。

从MySQL5.5开始引入，**当做增删查改时，会加MDL读锁；当变更表结构时，会加MDL写锁**。

- 读锁不互斥，因此可以有多个线程同时对一张表增删改查

- 读写互斥，即不能有多个线程同时更改表结构，或一个线程在增删改查而另一个线程在更改表结构

- MDL锁在事务提交时才会释放，在变更表结构时要特别小心，以免锁住线上的查询和更新，导致整张表不能读写。下面是一个示例：

  |        session A         |        session B         |        session C         |        session D         |
  | :----------------------: | :----------------------: | :----------------------: | :----------------------: |
  |          begin;          |                          |                          |                          |
  | select * from t limit 1; |                          |                          |                          |
  |                          | select * from t limit 1; |                          |                          |
  |                          |                          | alter table t add f int; |                          |
  |                          |                          |                          | select * from t limit 1; |

  session A 先开启了一个事务，执行了一次查询，并且没有马上提交，这时会对表 t 加一个 MDL 读锁。

  session B 也需要一个 MDL 读锁，读锁之间不互斥，可以正常执行查询。

  session C 要加一个字段，需要一个 MDL 写锁，读锁和写锁互斥，所以必须等待表 t 释放读锁之后才能继续。

  session D 需要一个读锁，这里需要注意的是，**表 t 上会有一个等待获取锁的锁队列，而获取MDL写锁的优先级要比获取读锁的优先级高**，所以导致session D 也被阻塞。

  最后的结果就是表 t 完全被锁住，完全不可读写了。如果客户端还有重试机制，一直在发起重试请求，MySQL的线程很快就会爆满，最后导致整个实例挂掉。



​		解决办法：

​		1、监控长事务(information_schema.innodb_trx)，要么先暂停DDL，要么kill掉这个长事务

​		2、但是对于一些热点表，kill未必管用，可能刚kill掉一个长事务，新的请求立马又来了。这种情况下，理想的办法是为 `alter table` 语句设定等待时间，如果在此期间能拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后再重试这个命令来重试这个过程。MariaDB 和 AliSQL 已经提供了这个功能，MySQL暂时没有。

```sql
ALTER TABLE t NOWAIT add column ...
ALTER TABLE t WAIT N add column ... 
```

MySQL可以通过调整 **`lock_wait_timeout`** 值来控制这个超时时间，默认值是 31536000s，即1年，显然这个时间太长了。







### 案例一

假如正在备库执行一个 `-single-transaction` 的逻辑备份，此时在主库上对表 t 执行了一个 DDL，备库会出现什么情况？

备库会根据 DDL 的 binlog 到达的时间点不同而出现不同的情况。

先拆解一下 `mysqldump -single-transaction` 在内部的执行逻辑：

1. set session transaction isolation level repeatable read;

2. start transaction with consistent snapshot;

   (其他表的备份逻辑)

3. SAVEPOINT sp;

   (时刻1)

4. show create table `t`;

   (时刻2)

5. select * from t;

   (时刻3)

6. rollback to savepoint sp;

   (时刻4)

   (其他表的备份逻辑)

   

 在时刻1到达：没有任何影响，此时表 t 上没有任何 MDL 锁，所以可正常执行，备份得到的是新的表结构；

 在时刻2到达：此时已经先备份完了 t 的表结构，DDL才到达，在执行第5步的时候会报错：`Table definition has changed,please retry transaction` ，mysqldump 终止；

 在时刻3到达：此时表结构和数据都已备份完成，但是 MDL 读锁还没释放(会在第6步后才释放)，所以 DDL 操作会阻塞，备份得到的是旧的表结构；

 在时刻4到达：MDL 读锁已被释放，DDL 可正常执行，备份得到的是旧的表结构。









### 行锁

由存储引擎实现，Innodb 支持，MyISAM 不支持。如果不支持行锁，就只能使用表级锁，也就意味着锁的粒度太大并发度就会降低。这也是为什么推荐使用 Innodb 的重要原因之一。

#### 两阶段锁

之前提到过一个两阶段提交，行锁有一个**两阶段锁**协议，也被称为 2PL。



##### 定义

两阶段指的是分为加锁阶段和解锁阶段，在加锁阶段只能加锁不能解锁，在解锁阶段只能解锁不能加锁。

单看定义很难理解，换成大白话说就是**行锁在需要的时候才加上，但并不是不需要了就立即释放，而是要事务结束后才会释放。**



##### 为什么需要两阶段锁？

重点就是在事务结束后才会释放所有行锁，而不是用完立即释放。**任何锁的本质就是保证并发操作的正确性，将并行改为串行**。二阶段锁用来保证并发更新操作的正确性，两个并发的更新操作，必须等其中一个提交后另一个才能继续，否则就**会发生更新被覆盖的情况**。

假设不存在两阶段锁协议，会发生如下情况：

同时发起2个操作，向同一个账户打200块，账户原余额有100块。

1. sessionA 发起打款操作，获取到写锁，用 `update` 更新账户余额为 300
2. `update` 完毕，假设不存在两阶段锁，用完立即释放，释放写锁，**此时事务尚未提交**
3. sessionB 发起打款操作，获取到写锁，根据一致性视图可见性规则：事务未提交，更新不可见。得到的账户余额仍为100，用 `update` 更新账户余额为 300
4. `update` 完毕，立即释放写锁
5. sessionA 提交，账户余额为 300
6. sessionB 提交，账户余额为 300

所以，因为存在两阶段锁协议，在第2步结束后，由于事务尚未提交，写锁仍未释放，则第3步的 `update` 操作必须等待 sessionA 提交后才能继续，此时 sessionA 读到的余额为300，再执行 `update` 后更新余额为500，这才是符合逻辑的结果。



##### 如何优化？

锁虽然保证了并发操作的正确性，但是由并行改为串行降低了并发度。所以另一个问题就是如何最大限度的提高并发度？

由于行锁是在需要的时候才加上，在事务结束后统一释放。所以针对包含多个更新的事务，可以**调整事务内更新语句的顺序，将会产生行锁竞争的语句尽量往后放，从而让等待行锁的时间最小化**，以达到提高并发度的目的。

示例：

假如有一个在线订票业务，订票逻辑可以简化为下列步骤：

1. 从账户余额扣掉票钱
2. 给系统余额加上票钱
3. 记录一条日志

假设同时发起2个订票请求，可以看到，在这个事务中，会产生行锁竞争的是第2步(直白说就是会 `update` 同一行)。按这个顺序的话，系统余额表上的行锁会从第2步开始加上，第3步完成后事务提交时释放。

调整下顺序，改为：

1. 记录一条日志
2. 从账户余额扣掉票钱
3. 给系统余额加上票钱

这时候系统余额表上的行锁持续时间就缩短为1步了，从第3步开始加上，到第3步完成后事务提交时释放。

虽然在这里看就是少了一小步(一条语句的执行时间)，但如果这个业务请求并发量很大的话，这个优化的效果就会非常明显。





#### 死锁

##### 为什么会出现死锁？

简单说就是出现**锁的循环等待**。示例如下：

|      |             sessionA             |             sessionB             |
| ---- | :------------------------------: | :------------------------------: |
| 1    |              begin;              |              begin;              |
| 2    | update t set k = k+1 where id=1; |                                  |
| 3    |                                  | update t set k = k+1 where id=2; |
| 4    | update t set k = k+1 where id=2; |                                  |
| 5    |                                  | update t set k = k+1 where id=1; |

由于事务都尚未提交，行锁还未释放。第4步要获取 `id=2` 的行锁，需要等待sessionB提交；第5步要获取 `id=1` 行锁，需要等待sessionA提交，死锁产生了。



##### 解决办法

1. ###### 等待直到超时，然后退出

   Innodb中有个参数用于设置这个超时时间：`innodb_lock_wait_timeout`，默认值为 50s。这个默认值对于业务来说是不能接受的，相当于卡顿50s。但是如果设成较小的值，又很有可能造成误伤：如果不是死锁，而就是普通的锁等待，此时并没有循环等待的情况，但是由于超过了阈值而被当成了死锁而提前退出了。所以这种方法一般不采用。

2. 主动死锁检测

   `innodb_deadlock_detect` 用于控制是否打开主动死锁检测，默认是 ON。

   这是一种相对较好的方式，但**需要注意的是它的资源消耗有可能会很大**。对于每个新加入进来的线程，都要先判断会不会由于自己的加入而导致死锁，这是一个时间复杂度为 O($n^2$) 的操作。假设有1000个并发线程同时更新同一行，这个死锁检测就是100万量级的。

   虽然最终检测的结果是没有死锁，但此期间需要消耗大量的CPU资源。所以当出现CPU消耗接近100%，TPS却很低的话，很有可能就是死锁检测导致的。

   那如何优化这种**热点行更新问题**？

   - 简单粗暴的方法就是如果确认不会出现死锁，直接关闭死锁检测。但这个方法明显危险系数很高，万一还是出现了死锁的话只能依靠超时机制，而如上面所述，超时机制的阈值很难设置。
   - **拆分热点行**。将一行拆分为多行，比如一条账户记录可以拆分为10条子账户记录，账户总额就等于10条子账户余额之和，在需要更新账户余额时，随机选择其中一条进行更新。这样就将一行上的死锁检测成本、锁等待个数、冲突概率都降为了原来的1/10。这种方案属于设计层面上的优化，需要结合业务逻辑做详细的设计和测试。





### 案例二

现需要删除前10000行数据，有以下三种方式：

- ```sql
  delete from t limit 10000;
  ```

- 在一个连接中循环执行20次 `delete from t limit 500;`

- 在20个连接中同时执行 `delete from t limit 500;`

哪种方式好一些？

第一种：执行时间较长，意味着占用锁(MDL读锁、X锁)的时间会比较长；而且大事务在从库上回放的时间也较长，在此期间会导致主从延迟；

第三种：人为的制造了行锁冲突，而且大概率会重复删除，达不到删除前10000行数据的目的；

第二种方式较好。

